# Proposal: API Rethink

Author(s): [Brad Beam](@bradbeam)

## Abstract

In the 0.1 API, we offer just enough to get going. There are certain gaps in
the provided functionality with tasks that an operator would need to perform.
With embracing the no shell approach, we need to rethink how we can provide
better information/value to our users. To that end, we will not be implementing
the entire `coreutils` package. Instead we will attempt to provide a more
holistic view of each interaction.

## Background

[An introduction of the necessary background and the problem being solved by the proposed change.]

With the focus on immutable infrastructure, we do not offer up a shell on the
host. This allows us to maintain a minimal approach to Talos as well as reduce
the potential for drift. In doing so, there needs to be some facility to provide
information about the host and host management. This is currently accomplished
via `osctl` and `osd` ( and by proxy `init` ).

Our current implementation supports some troubleshooting tools, but lacks a
complete set. We started going down the route of implementing pieces of
`coreutils` since that is common and familiar to every Linux user.
Unfortunately, not only is this inefficient in terms of the programmatic effort
in porting these tools to Go, but this also does not push the bar to make
Talos better.  There are common patterns that every Linux administrator has
developed over the course of their career to get access to the information
they need. These patterns take the form of shell scripts, handy one liners,
notebook entries, blog posts, etc. We should be able to build upon this wisdom
and provide value from the start.

## Proposal

[A precise statement of the proposed change.]
At a high level, we'd like to:

- Consolidate the command usage into a familiar and consistent format.
  - Common verbs where possible
  - Appropriately named groupings of resources

- Provide interpreted data to make the 'at a glance' interaction more fruitful
  while still providing the ability to obtain the raw data for deeper or custom
  analysis.

- Provide a complete set of operational tools for both management and
  troubleshooting.

There will be a slight shift in the 'app' definition for Talos components.
Each app must implement a gRPC endpoint for exposing state and other related
information. This should allow for and enable commonality between the various
interactions.

A minimum example interface the gRPC endpoint must implement would look
something like the following

```
type TalosAPI interface {
	// Verbose information about a given resource
	Show(Resources...) (Response, err)
	// Ability to perform a self test
	Test()
}
```

#### OSD

OSD remains the hub for all app interaction. It will provide the public API for
users and osctl to consume. It will also provide a private API for apps to
interact with one another. Functionally, OSD will be where all of the 'magic'
happens with regards to combining multiple disparate app requests into a single
valuable response.
To better explain the above, we can use an example API request to display an
overall picture of a host. We'd want to display typical host level stats along
with some network information, perhaps even the time with a +/- offset from
upstream servers. The workflow would follow something like:

- client requests machine info from OSD, `MachineInfo()`
- `MachineInfo()` calls out to
  - `machined.Show(cpu)`
  - `machined.Show(memory)`
  - `machined.Show(processes)`
  - `networkd.Show(interfaces)`
  - `networkd.Show(routes)`
  - `ntp.Show()`
- OSD compiles/formats an appropriate response back to the client

This should allow us to properly abstract the underlying backend systems.
We would expose the OSD frontend as the contract for our client interaction,
so as long as we maintain parity in that contract, we can adjust things as
needed on the underlying apps.


( unsure on the below, thoughts? )
OSD will also implement a private gRPC endpoint ( via unix socket ) to allow
app-to-app communication as well as a registration endpoint. The registration
endpoint will allow services to register with OSD when they are up and healthy.
This will most likely translate into some client instantiation when called.

#### Machined

Machined would be responsible for the host as a whole. This includes the
following resources:

**| Kernel | Devices | Host Info | Services | Processes |**

From the Kernel perspective, this should provide the ability to access kernel
logs, kernel configuration, modules, tunables, command line, etc.

From the Device perspective, this should focus on block devices, but anything
under `/dev` and `/sys` should be fair game.

From the host info perspective, this should include the miscellaneous
information about a host - firmware versions, serial number, make/model, CPUs,
Memory DIMMs, etc.

From the Services perspective, this should provide an interface to service
lifecycle management. Service logs, controls ( start/stop/restart ), tests,
current health, state changes, etc.

From the Process perspective, this should provide the ability to gather stats
about currently running processes. Things like a full process list, a filtered
list, process information ( memory, cpu, threads, exe,.. /proc/*pid*/ details ).

#### Proxyd

Proxyd would be responsible for proxyd management.

- Ability to list current backends and the status
- Ability to reset connection counters
- Ability to (un-)'blacklist' a backend

#### Networkd

Networkd would be responsible for all network interactions.

**| Interfaces | Routes | DHCP | Firewall |**

From the interface perspective, this should provide the ability to gather
specific information from the network interface. Things like IP, Netmask,
MTU, link status, etc.
Do we expose interface configuration functionality?

From the route perspective, this should provide the ability to enumerate
routes on the host as well as show statistics on route metrics and origins.

From the DHCP perspective, this should provide information on the current DHCP
lease ( effectively the DHCP response ) and remainder lease time.

From a firewall perspective, this should provide the current table definitions
along with the ability to filter for a specific chain/IP/etc.

## Rationale

[A discussion of alternate approaches and the trade offs, advantages, and disadvantages of the specified approach.]

## Compatibility

[A discussion of the change with regard to the change]

## Implementation

[A description of the steps in the implementation, who will do them, and when.]

To recap,

- Each Talos application will implement a local gRPC server ( running on a unix
  socket )
- Each Talos application will implement a minimum set of gRPC endpoints
- OSD will act as the middleware between client interactions and the backing
  services


## Open issues (if applicable)

[A discussion of issues relating to this proposal for which the author does not
know the solution. This section may be omitted if there are none.]
